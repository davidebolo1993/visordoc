(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{389:function(t,s,a){"use strict";a.r(s);var e=a(45),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"use-cases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#use-cases"}},[t._v("#")]),t._v(" Use cases")]),t._v(" "),a("p",[t._v("Following are described some use cases, examples illustrating how to run VISOR modules.")]),t._v(" "),a("h2",{attrs:{id:"visor-hack"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#visor-hack"}},[t._v("#")]),t._v(" VISOR HACk")]),t._v(" "),a("p",[t._v("As described in the "),a("RouterLink",{attrs:{to:"/usage/usage.html"}},[t._v("General usage section")]),t._v(", HACk requires at least one variant file in BED format and a reference template FASTA as inputs. We can start by downloading and subsetting a reference genome.")],1),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#create the test folder")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mkdir")]),t._v(" visortest "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" visortest\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#download the human reference genome in FASTA format")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -LO ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/GRCh38_full_analysis_set_plus_decoy_hla.fa\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#extract 2 small chromosomes")]),t._v("\nsamtools faidx GRCh38_full_analysis_set_plus_decoy_hla.fa chr21 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" chr21.fa\nsamtools faidx GRCh38_full_analysis_set_plus_decoy_hla.fa chr22 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" chr22.fa\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#combine the 2 chromosomes in a small reference")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" chr21.fa chr22.fa "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" small.reference.fa\nsamtools faidx small.reference.fa\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#get a BED with regions we want to exclude when creating variants")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -LO https://gist.githubusercontent.com/chapmanb/4c40f961b3ac0a4a22fd/raw/2025f3912a477edc597e61d911bd1044dc943440/sv_repeat_telomere_centromere.bed\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("echo")]),t._v(" -e "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chr21'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[t._v("\\n")]),t._v('chr22"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" tmp.txt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("grep")]),t._v(" -w -f tmp.txt sv_repeat_telomere_centromere.bed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" sortBed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" exclude.bed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("rm")]),t._v(" tmp.txt\n")])])]),a("h3",{attrs:{id:"manually-building-hack-bed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#manually-building-hack-bed"}},[t._v("#")]),t._v(" Manually building HACk BED")]),t._v(" "),a("p",[t._v("For a limited number of variants, manually building HACk BED as described in the "),a("RouterLink",{attrs:{to:"/usage/usage.html"}},[t._v("General usage section")]),t._v(" is not a big issue.")],1),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#generate a variant BED with 3 variants on chr22")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("echo")]),t._v(" -e "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chr22'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("15000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("16000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("deletion"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("None"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("0"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[t._v("\\n")]),t._v("chr22"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("20000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("21000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("inversion"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("None"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("0"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[t._v("\\n")]),t._v("chr22"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("30000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("31000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("tandem duplication"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("2"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('0"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" HACk.h1.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#then run HACk; we can use chr22.fa as reference, as alterations involve only this chromosome")]),t._v("\nVISOR HACk -g chr22.fa -b HACk.h1.bed -o hack.1.out\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#as we gave a single BED to HACk without variants involving other haplotypes, HACk generates a single FASTA haplotype (h1.fa) and its index (h1.fa.fai) in the output folder")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#we can give to HACk as many BED as many haplotypes we want to create")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("echo")]),t._v(" -e "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chr22'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("40000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("41000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("deletion"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("None"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('0"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" HACk.h2.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#then run HACk with a double-BED input")]),t._v("\nVISOR HACk -g chr22.fa -b HACk.h1.bed HACk.h2.bed -o hack.2.out\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#2 FASTA haplotypes (h1.fa and h2.fa) and their indexes are stored in the output folder")]),t._v("\n")])])]),a("h3",{attrs:{id:"automatically-building-hack-bed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#automatically-building-hack-bed"}},[t._v("#")]),t._v(" Automatically building HACk BED")]),t._v(" "),a("p",[t._v("When dealing with hundreds of variants, manually building a BED for HACk can be hard. One can then choose to generate a random variant BED with proportions of events or to adapt variants taken from "),a("a",{attrs:{href:"http://www.internationalgenome.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("public repositories"),a("OutboundLink")],1),t._v(" into a BED properly formatted for HACk.")]),t._v(" "),a("h4",{attrs:{id:"generate-a-random-variant-bed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#generate-a-random-variant-bed"}},[t._v("#")]),t._v(" Generate a random variant BED")]),t._v(" "),a("p",[t._v("A "),a("a",{attrs:{href:"https://github.com/davidebolo1993/VISOR/blob/master/scripts/randomregion.r",target:"_blank",rel:"noopener noreferrer"}},[t._v("R script"),a("OutboundLink")],1),t._v(" capable to build a BED file properly formatted for HACk with a user-defined number of random variants is included in the script folder of "),a("a",{attrs:{href:"https://github.com/davidebolo1993/VISOR",target:"_blank",rel:"noopener noreferrer"}},[t._v("VISOR"),a("OutboundLink")],1),t._v(". All variants described in the "),a("RouterLink",{attrs:{to:"/usage/usage.html"}},[t._v("General usage section")]),t._v(" can be generated using this script.")],1),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#this script requires a R version >= 3.5.0. It will try to install the needed packages if not already in your package list")]),t._v("\nRscript VISOR/scripts/randomregion.r -h \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#randomregion.r requires to know your chromosomes dimensions. We can get these easily. For example, using the index of small.genome.fa.fai")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -f1,2 small.reference.fa.fai "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" chrom.dim.tsv\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#generate 100 non-overlapping random variants on chr21 and chr22, with mean length 200 Kb, choosing from deletion, inversion, inverted tandem duplication, translocation copy-paste and reciprocal translocation, with a certain ratio and excluding regions in exclude.bed")]),t._v("\nRscript VISOR/scripts/randomregion.r -d chrom.dim.tsv -n "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" -l "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200000")]),t._v(" -x exclude.bed -v "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'deletion,inversion,inverted tandem duplication,translocation copy-paste,reciprocal translocation'")]),t._v(" -r "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'40:20:20:10:10'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" sortBed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" HACk.random.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#reciprocal translocations are placed by default on a haplotype different then the one specified with the -i parameter (default to 1 -that is, h1 in the final BED). Other translocations types are placed on the same haplotype. Run HACk with this BED")]),t._v("\nVISOR HACk -g small.reference.fa -b HACk.random.bed -o hack.3.out\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#2 FASTA haplotypes (h1.fa and h2.fa) with their indexes are stored in the output folder, as 2 haplotypes are present in BED")]),t._v("\n")])])]),a("h4",{attrs:{id:"generate-a-variant-bed-from-publicly-available-variant-data"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#generate-a-variant-bed-from-publicly-available-variant-data"}},[t._v("#")]),t._v(" Generate a variant BED from publicly available variant data")]),t._v(" "),a("p",[t._v("Following is described a standard procedure one can use to get some variant types from publicly available variant data sets in "),a("a",{attrs:{href:"https://samtools.github.io/hts-specs/VCFv4.3.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("VCF/BCF format"),a("OutboundLink")],1),t._v(" and convert them to BED properly formatted for HACk.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#First, get phased structural variants in VCF format")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -LO http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/integrated_sv_map/supporting/GRCh38_positions/ALL.wgs.integrated_sv_map_v2_GRCh38.20130502.svs.genotypes.vcf.gz\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -LO http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/integrated_sv_map/supporting/GRCh38_positions/ALL.wgs.integrated_sv_map_v2_GRCh38.20130502.svs.genotypes.vcf.gz.tbi\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#subset to a single sample (HG00732, for example). Install bcftools if not in PATH")]),t._v("\nbcftools view -O b -o HG00732.sv.bcf -s HG00732 -m2 -M2 -c "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" -C "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" ALL.wgs.integrated_sv_map_v2_GRCh38.20130502.svs.genotypes.vcf.gz\nbcftools index HG00732.sv.bcf\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#get haplotype-specific variants and write to BED")]),t._v("\nbcftools query -f "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'%CHROM\\t%POS\\t%INFO/END\\t%INFO/SVTYPE[\\t%SAMPLE=%GT]\\n'")]),t._v(" HG00732.sv.bcf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("grep")]),t._v(" -w "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DEL"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("grep")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1|0"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'OFS=FS=\"\\t\"'")]),t._v("'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("if "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(" -"),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"deletion"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"None"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' | sed '")]),t._v("s/^/chr/"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' > HACk.phased.h1.bed\nbcftools query -f '")]),t._v("%CHROM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%POS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%INFO/END"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%INFO/SVTYPE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%SAMPLE"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("%GT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('\' HG00732.sv.bcf | grep -w "DEL" | grep "0|1" | awk \'')]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("OFS")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("FS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("if "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(" -"),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"deletion"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"None"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' | sed '")]),t._v("s/^/chr/"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' > HACk.phased.h2.bed\nbcftools query -f '")]),t._v("%CHROM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%POS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%INFO/END"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%INFO/SVTYPE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%SAMPLE"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("%GT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('\' HG00732.sv.bcf | grep -w "INV" | grep "1|0" | awk \'')]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("OFS")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("FS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("if "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(" -"),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inversion"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"None"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' | sed '")]),t._v("s/^/chr/"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' >> HACk.phased.h1.bed\nbcftools query -f '")]),t._v("%CHROM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%POS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%INFO/END"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%INFO/SVTYPE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%SAMPLE"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("%GT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('\' HG00732.sv.bcf | grep -w "INV" | grep "0|1" | awk \'')]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("OFS")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("FS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("if "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(" -"),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$3")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inversion"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"None"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' | sed '")]),t._v("s/^/chr/' "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" HACk.phased.h2.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#run HACk")]),t._v("\nVISOR HACk -g GRCh38_full_analysis_set_plus_decoy_hla.fa -b HACk.phased.h1.bed HACk.phased.h2.bed -o hack.4.out\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#among variants that are found to overlap, only the first (is kept)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#2 FASTA haplotypes (h1.fa and h2.fa) with their indexes are stored in the output folder")]),t._v("\n")])])]),a("h3",{attrs:{id:"insert-single-nucleotide-variants-and-structural-variants-in-haplotypes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#insert-single-nucleotide-variants-and-structural-variants-in-haplotypes"}},[t._v("#")]),t._v(" Insert single nucleotide variants and structural variants in haplotypes")]),t._v(" "),a("p",[t._v("HACk's default behaviour is to skip overlapping variants; thus, while is always possible to insert single nucleotide polimorphisms flanking certain structural variants, is impossible to put them in regions with structural variants already inserted. A procedure capable to overcome HACk behaviour is described below.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#First, get phased single nucleotide polimprhisms in VCF format for chr22")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -LO ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/release/20181203_biallelic_SNV/ALL.chr22.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -LO ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/release/20181203_biallelic_SNV/ALL.chr22.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz.tbi\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#subset to a single sample (HG00732, for example)")]),t._v("\nbcftools view -O b -o HG00732.snp.bcf -s HG00732 -m2 -M2 -c "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" -C "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" ALL.chr22.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz\nbcftools index HG00732.snp.bcf\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#get haplotype-specific single nucleotide polimorhpisms and write to BED")]),t._v("\nbcftools query -f "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'%CHROM\\t%POS\\t%REF\\t%ALT[\\t%SAMPLE=%GT]\\n'")]),t._v(" HG00732.snp.bcf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("grep")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1|0"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'OFS=FS=\"\\t\"'")]),t._v("'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(" -1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SNP"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$4")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' > HACk.snps.h1.bed\nbcftools query -f '")]),t._v("%CHROM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%POS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%REF"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%ALT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("t%SAMPLE"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("%GT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' HG00732.snp.bcf | grep \"0|1\" | awk '")]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("OFS")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("FS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(" -1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SNP"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$4")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("' "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" HACk.snps.h2.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#generate 2 haplotypes (h1.fa and h2.fa) with single nucleotide polimorphisms")]),t._v("\nVISOR HACk -g chr22.fa -b HACk.snps.h1.bed HACk.snps.h2.bed -o templateswithsnp\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#use HACk.h1.bed and HACk.h2.bed generated before to insert some simple structural variant. Insert in haplotype 1")]),t._v("\nVISOR HACk -g templateswithsnp/h1.fa -b HACk.h1.bed -o haplo1\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#and in haplotype 2")]),t._v("\nVISOR HACk -g templateswithsnp/h2.fa -b HACk.h2.bed -o haplo2\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#re-organize the 2 folders, creating one with 2 FASTA haplotypes (h1.fa and h2.fa)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" haplo2/h1.fa haplo2/h2.fa "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" haplo2/h1.fa.fai haplo2/h2.fa.fai "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" haplo2/h2.fa* haplo1/ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" haplo1 hack.5.out "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("rm")]),t._v(" -r haplo2\n")])])]),a("h2",{attrs:{id:"visor-shorts-and-laser"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#visor-shorts-and-laser"}},[t._v("#")]),t._v(" VISOR SHORtS and LASeR")]),t._v(" "),a("p",[t._v("As described in the "),a("RouterLink",{attrs:{to:"/usage/usage.html"}},[t._v("General usage section")]),t._v(", SHORtS and LASeR require a BED describing regions to simulate, a reference template FASTA (the same used for HACk) and (at least) a folder containing haplotypes generated with HACk. Generating the required BED is pretty straightforward.")],1),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#simulate reads aligning to the entire chr22 from haplotypes in test.5.out. As we inserted some structural variants in the 2 haplotypes, their chromosome sizes can differ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -f1,2 hack.5.out/*.fai chr22.fa.fai "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" haplochroms.dim.tsv\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#chr22 from haplotype 2 is 1000000 base pairs smaller than the one from haplotype 1. For each chromosome, we get the maximum dimension. This is necessary to calculate accurately the number of reads to simulate for each chromosome")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" haplochroms.dim.tsv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sort")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'$2 > maxvals[$1] {lines[$1]=$0; maxvals[$1]=$2} END { for (tag in lines) print lines[tag] }'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" maxdims.tsv\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#create a BED to simulate reads from chr22, without coverage fluctuations (that is, capture bias value in 4th column is 100.0) and without normal contamination (that is, purity value in 5th column is 100.0) ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'OFS=FS=\"\\t\"'")]),t._v("'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"100.0"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"100.0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("' maxdims.tsv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" shorts.laser.simple.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#multiple entries can of course be specified in the same BED")]),t._v("\n")])])]),a("p",[t._v("Once the requirements are met, one can run SHORtS or LASeR.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#run SHORtS first, using the default read simulation settings. Use low coverage to accelerate the alignment step. Use 7 cores for alignment")]),t._v("\nVISOR SHORtS -g chr22.fa -s hack.5.out -b shorts.laser.simple.bed -o shorts.1.out --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#run LASeR with the default read simulation settings as well. Tag final BAM by haplotype/clone (HP/CL-tags). Using multiple cores to accelerate both simulation and alignment")]),t._v("\nVISOR LASeR -g chr22.fa -s hack.5.out -b shorts.laser.simple.bed -o laser.1.out --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" --tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#a sorted BAM is stored in each output folder")]),t._v("\n")])])]),a("p",[t._v("Generating results with different purity/capture biases combination can be done by simply looping through different, pre-existent, BED files for SHORtS/LASeR. For example, simulating results with different purity values can be done as below.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#bed 100.0 purity is shorts.laser.simple.bed")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("set")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$VAR2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cp")]),t._v(" shorts.laser.simple.bed shorts.laser.purity100.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#generate also one with purity 80.0 and one with purity 50.0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'OFS=FS=\"\\t\"'")]),t._v("'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$5")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"80.0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("print"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' shorts.laser.purity100.bed > shorts.laser.purity80.bed && awk '")]),t._v("OFS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("FS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$5")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"50.0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("print"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("' shorts.laser.purity100.bed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" shorts.laser.purity50.bed\n"),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("VAR1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"shorts.laser.purity100.bed shorts.laser.purity80.bed shorts.laser.purity50.bed"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("VAR2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PUR100 PUR80 PUR50"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("set")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$VAR2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token for-or-select variable"}},[t._v("i")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$VAR1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n\tVISOR SHORtS -g chr22.fa -s hack.5.out -b "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$i")]),t._v(" -o "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(" --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("shift")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("done")]),t._v("\n")])])]),a("h3",{attrs:{id:"simulate-heterogeneous-bulk-data-with-shorts-and-laser"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#simulate-heterogeneous-bulk-data-with-shorts-and-laser"}},[t._v("#")]),t._v(" Simulate heterogeneous bulk data with SHORtS and LASeR")]),t._v(" "),a("p",[t._v("Both SHORtS and LASeR support simulations of bulk data with multiple sub-clones, which is useful to mimic tumour heterogeneity. Reads coming from different clones have a different CL-tag.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#first sub-clone is hack.5.out (diploid clone, with some variants in both haplotypes); second clone is hack.1.out (aneuploid clone with some variants); third clone is templateswithsnp (diploid reference clone). First, get the maximum chromosomes dimensions from multiple clones, as described above")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -f1,2 hack.5.out/*.fai hack.1.out/*.fai templateswithsnp/*.fai chr22.fa.fai "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sort")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'$2 > maxvals[$1] {lines[$1]=$0; maxvals[$1]=$2} END { for (tag in lines) print lines[tag] }'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awk")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'OFS=FS=\"\\t\"'")]),t._v("'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("print "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$2")]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"100.0"')]),t._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"100.0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("' "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" shorts.laser.multi.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#run SHORtS first, with multiple samples as input. Each sample is considered as a sub-clone. Ordered percentages describing the relative abundance of each sub-clone are specified with the --clonefraction parameter")]),t._v("\nVISOR SHORtS -g chr22.fa -s hack.5.out hack.1.out templateswithsnp -b shorts.laser.multi.bed -o shorts.2.out --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" --clonefraction "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("80.0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10.0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10.0")]),t._v(" --tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#simulate also with LASeR")]),t._v("\nVISOR LASeR -g chr22.fa -s hack.5.out hack.1.out templateswithsnp -b shorts.laser.multi.bed -o laser.2.out --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" --clonefraction "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("80.0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10.0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10.0")]),t._v(" --tag\n")])])]),a("h3",{attrs:{id:"simulate-single-cell-strand-seq-data-with-shorts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#simulate-single-cell-strand-seq-data-with-shorts"}},[t._v("#")]),t._v(" Simulate single-cell strand-seq data with SHORtS")]),t._v(" "),a("p",[t._v("SHORtS is suitable to simulate single-cell strand-seq data. Strand-seq is a single-cell template strand sequencing technology with directional genomic libraries that allow a clear distinction between the individual homologs of a chromosome. For each haplotype in the given sample, SHORtS generate 2 BAM (one for each strand, usually called Watson and Crick) with the correct read pairs orientation (F1-R2 for Watson and F2-R1 for Crick). Be also sure to set the coverage to a proper, low, value (~ 0.04X, usually)")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#simulte single-cell strand-seq data, adding 5% noise (read pairs with incorrect orientation) with the --noise parameter. We can use a coverage higher than usual one to better visualize the results after the simulations. Use hack.5.out for which we have a ready-to-use BED for SHORtS")]),t._v("\nVISOR SHORtS -g chr22.fa -s hack.5.out -b shorts.laser.simple.bed -o shorts.3.out --strandseq --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --noise "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#this will create 2 subfolders (h1 for first haplotype, h2 for second ...) with a watson (W) and a crick (C) BAM in each. It is also possible to simulate multiple single-cells, some of them originating from a modified clone (sharing the same alterations) and some others from a reference clone. For instance, simulate 2 cells, half (50%) from a reference clone.")]),t._v("\nVISOR SHORtS -g chr22.fa -s hack.5.out -b shorts.laser.simple.bed -o shorts.4.out --strandseq --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --noise "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.0")]),t._v(" --cells "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" --refcells "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50.0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#It is also possible to simulate sister chromatid exchange events for cells, haplotypes and regions specified in a separate BED. For h1.fa of the first sample cell, for example:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("echo")]),t._v(" -e "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chr22'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("48000000"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("50818468"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("sample_cell1"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('haplotype1"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sce.c1h1.bed\nVISOR SHORtS -g chr22.fa -s hack.5.out -b shorts.laser.simple.bed -o shorts.5.out --strandseq --threads "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" --coverage "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --noise "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.0")]),t._v(" --sce sce.c1h1.bed\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#For the generated cell, we can eventually merge the W/C haplotypes")]),t._v("\nsamtools merge shorts.5.out/sample_cell1/WC.srt.bam shorts.5.out/sample_cell1/h1/W.srt.bam shorts.5.out/sample_cell1/h2/C.srt.bam "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" samtools index shorts.5.out/sample_cell1/WC.srt.bam\n")])])]),a("p",[t._v("A method to "),a("a",{attrs:{href:"https://github.com/davidebolo1993/VISOR/blob/master/scripts/sscounter.py",target:"_blank",rel:"noopener noreferrer"}},[t._v("visualize"),a("OutboundLink")],1),t._v(" events in strand-seq data is included in the script folder of "),a("a",{attrs:{href:"https://github.com/davidebolo1993/VISOR",target:"_blank",rel:"noopener noreferrer"}},[t._v("VISOR"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#a WC.srt.bam is now in the output folder. Plot an interactive visualization of the 2 strands. As we have just chr22, limit the analysis to this chromosome")]),t._v("\npython VISOR/scripts/sscounter.py -b shorts.5.out/sample_cell1/WC.srt.bam --chromosome chr22 --binsize "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v(" -o chr22.html\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#a chr22.html is stored. Can be opened using the default web browser. For example, using firefox")]),t._v("\nfirefox chr22.html\n")])])]),a("h2",{attrs:{id:"visor-xenia-beta"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#visor-xenia-beta"}},[t._v("#")]),t._v(" VISOR XENIA (BETA)")]),t._v(" "),a("p",[t._v("As described in the "),a("RouterLink",{attrs:{to:"/usage/usage.html"}},[t._v("General usage section")]),t._v(", XENIA requires one BED describing regions to simulate and a folder containing haplotypes generated with HACk. Once the requirements are met, one can run XENIA to simulate linked reads. Linked reads simulations have been inferred from "),a("a",{attrs:{href:"https://assets.ctfassets.net/an68im79xiti/6ceYcRzVAc6MaSMeyO0akE/4d9f269143be9e1750a415e1d5aa6762/CG00044_10x_Techical_Note_LinkedReads.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("10X Genomics documentation"),a("OutboundLink")],1)],1),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#use hack.5.out. FASTQ simulation by GEM can be accelerated using multiple cores. The same BED constructed for SHORtS and LASeR can be used. s")]),t._v("\nVISOR XENIA -s hack.5.out -b shorts.laser.simple.bed -o xenia.1.out \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#a FASTQ pair (R1-R2) for each haplotype (L001-L002) is stored in the output folder")]),t._v("\n")])])]),a("p",[t._v("Output from XENIA is ready to be aligned with 10X aligner "),a("a",{attrs:{href:"https://support.10xgenomics.com/genome-exome/software/pipelines/latest/what-is-long-ranger",target:"_blank",rel:"noopener noreferrer"}},[t._v("Long Ranger"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#create reference folder for Long Ranger")]),t._v("\nlongranger-2.2.2/longranger mkref chr22.fa\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#convert BCF file of phased SNPs to VCF, required by Long Ranger")]),t._v("\nbcftools view -O "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("v")]),t._v(" -o HG00732.snp.vcf HG00732.snp.bcf\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#align using WGS Long Ranger module. HG00732.snp.vcf has to be given as a full path")]),t._v("\nlongranger-2.2.2/longranger wgs --reference refdata-chr22 --fastqs xenia.1.out --precalled HG00732.snp.vcf --somatic --sex f --id longranger.out\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#browse the generate loupe.loupe file using the Diploid Genome Viewer Loupe that can be downloaded from Long Ranger page (https://support.10xgenomics.com/genome-exome/software/downloads/latest)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("LOUPE_SERVER")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("longranger.out/outs/\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sh")]),t._v(" loupe-2.1.1/start_loupe.sh\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#select the loupe.loupe file and browse. As we simulated just one chromosome, the number of GEMs detected will be lower than expected for an entire genome")]),t._v("\n")])])]),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Please be aware that XENIA is released as a BETA version and some issues may emerge while running; if so, please open an "),a("a",{attrs:{href:"https://github.com/davidebolo1993/VISOR/issues",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue"),a("OutboundLink")],1),t._v(" or get in touch with me at davidebolognini7@gmail.com")])])])}),[],!1,null,null,null);s.default=n.exports}}]);